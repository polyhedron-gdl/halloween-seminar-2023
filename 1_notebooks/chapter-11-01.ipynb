{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ca58b15",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/polyhedron-gdl/halloween-seminar-2023/blob/main/1_notebooks/chapter-11-01.ipynb\">\n",
    "        <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3edcac",
   "metadata": {},
   "source": [
    "# Summarize PDF Document with OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639d884f",
   "metadata": {},
   "source": [
    "This notebook is based on the blog [The Ultimate Guide to PDF Summarization with OpenAI API: Simplify Your Reading Process](https://medium.com/@kapildevkhatik2/the-ultimate-guide-to-pdf-summarization-with-openai-api-simplify-your-reading-process-80021210cd11#id_token=eyJhbGciOiJSUzI1NiIsImtpZCI6IjA1MTUwYTEzMjBiOTM5NWIwNTcxNjg3NzM3NjkyODUwOWJhYjQ0YWMiLCJ0eXAiOiJKV1QifQ.eyJpc3MiOiJodHRwczovL2FjY291bnRzLmdvb2dsZS5jb20iLCJuYmYiOjE2ODcxNzUzNzMsImF1ZCI6IjIxNjI5NjAzNTgzNC1rMWs2cWUwNjBzMnRwMmEyamFtNGxqZGNtczAwc3R0Zy5hcHBzLmdvb2dsZXVzZXJjb250ZW50LmNvbSIsInN1YiI6IjEwMTY0ODk4MDkzODU4MzAwMTMyMSIsImVtYWlsIjoiZ2lvdmFubmkuZGVsbGFsdW5nYUBnbWFpbC5jb20iLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiYXpwIjoiMjE2Mjk2MDM1ODM0LWsxazZxZTA2MHMydHAyYTJqYW00bGpkY21zMDBzdHRnLmFwcHMuZ29vZ2xldXNlcmNvbnRlbnQuY29tIiwibmFtZSI6Ikdpb3Zhbm5pIERlbGxhIEx1bmdhIiwicGljdHVyZSI6Imh0dHBzOi8vbGgzLmdvb2dsZXVzZXJjb250ZW50LmNvbS9hL0FBY0hUdGVzWVZMY1dmZkphY2ZfSmU4WWpvbHF4QUNTSTN3MHdsWlJRWWxjdXc9czk2LWMiLCJnaXZlbl9uYW1lIjoiR2lvdmFubmkiLCJmYW1pbHlfbmFtZSI6IkRlbGxhIEx1bmdhIiwiaWF0IjoxNjg3MTc1NjczLCJleHAiOjE2ODcxNzkyNzMsImp0aSI6ImM3NTBkZjNiNTBiODA4NmZhM2YwMTI3OTY4MDFmMzUyMjIyOGIzYTEifQ.W6vLMMjlVXO5upLzoW64ctuSV-fukd1n7WSawt5qGCE_5ThBHpi5FgFiFnRXKy5zAmnAawI5CDQ8YgQe14WuZcSa2jpQPfcmhI64LZIXR-KTmxta4OWKYWCavmYwaoG9SyrLEPr7OA2nw2ye9lQB0sfZqVWmYehVs04GR5etWEKEtgPkm1DLYb2aTPNCvrAyXjUqUhF29Uy8vQZ3OsFhGMB2cfMJHqGpQJMcCmJ3TCEDJlNOImzSWyVTLZx9pgbcYa5QtMCeOuWbF25MpQBSs-SGUB8PAqTg6XF_QbTe0iwzzsA0hfPsLMCxpk28Ji5GRvkV1V31xJDj5DpSx0Kukw) by Kapil Khatik. Let's start with the basic import..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9b7cfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz\n",
    "import openai\n",
    "import json\n",
    "\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f11eaa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98711b8",
   "metadata": {},
   "source": [
    "- **Fitz**: Fitz is a Python library for working with PDF files. It allows you to read, write, and manipulate PDF documents in your Python scripts.\n",
    "\n",
    "- **OpenAI**: OpenAI is a powerful AI platform that provides access to state-of-the-art language models, such as GPT-3, for natural language processing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3668c000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e421fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/Guidelines on IRRBB and CSRBB.pdf\n"
     ]
    }
   ],
   "source": [
    "path = './data/'\n",
    "filename = 'Guidelines on IRRBB and CSRBB.pdf'\n",
    "\n",
    "# Join the path and filename\n",
    "filename = os.path.join(path, filename)\n",
    "\n",
    "# Print the resulting filepath\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb95abb4",
   "metadata": {},
   "source": [
    "## Step 1: Reading the Text Content of a PDF File with Fitz in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7587f85c",
   "metadata": {},
   "source": [
    "See the slides for a full description of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdac49ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\n",
    "\n",
    "# Open the PDF file\n",
    "with fitz.open(filename) as pdf_file:\n",
    "    # Get the number of pages in the PDF file\n",
    "    num_pages = pdf_file.page_count\n",
    "\n",
    "    # Loop through each page in the PDF file\n",
    "    for page_num in range(num_pages):\n",
    "        # Get the current page\n",
    "        page = pdf_file[page_num]\n",
    "\n",
    "        # Get the text from the current page\n",
    "        page_text = page.get_text()\n",
    "  \n",
    "        # Append the text to context\n",
    "        context += page_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee211c6",
   "metadata": {},
   "source": [
    "## Step 2: Breaking Down Lengthy PDF Text into Manageable Chunks for Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e16685",
   "metadata": {},
   "source": [
    "The next step involves feeding the context into the “split_text” function, which is responsible for dividing the text into paragraphs containing 5000 characters each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4158b832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text, chunk_size=5000):\n",
    "    \n",
    "    '''\n",
    "    Splits the given text into chunks of approximately the specified chunk size.\n",
    "\n",
    "    Args:\n",
    "    text (str): The text to split.\n",
    "\n",
    "    chunk_size (int): The desired size of each chunk (in characters).\n",
    "\n",
    "    Returns:\n",
    "    List[str]: A list of chunks, each of approximately the specified chunk size.\n",
    "    '''\n",
    "\n",
    "    chunks = []\n",
    "    current_chunk = StringIO()\n",
    "    current_size = 0\n",
    "    sentences = sent_tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        sentence_size = len(sentence)\n",
    "        if sentence_size > chunk_size:\n",
    "            while sentence_size > chunk_size:\n",
    "                chunk = sentence[:chunk_size]\n",
    "                chunks.append(chunk)\n",
    "                sentence = sentence[chunk_size:]\n",
    "                sentence_size -= chunk_size\n",
    "                current_chunk = StringIO()\n",
    "                current_size = 0\n",
    "        if current_size + sentence_size < chunk_size:\n",
    "                current_chunk.write(sentence)\n",
    "                current_size += sentence_size\n",
    "        else:\n",
    "                chunks.append(current_chunk.getvalue())\n",
    "                current_chunk = StringIO()\n",
    "                current_chunk.write(sentence)\n",
    "                current_size = sentence_size\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.getvalue())\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13379a2b",
   "metadata": {},
   "source": [
    "The code defines a Python function named `split_text` that takes a lengthy text and splits it into smaller chunks of approximately the same size. The function uses the `sent_tokenize` function to split the text into sentences and then iterates over each sentence to create the chunks. The size of each chunk can be specified in the function arguments, with the default size being 5000 characters. The function returns a list of chunks, with each chunk having approximately the same size as specified. This function can be used for summarizing lengthy PDF texts by breaking them down into smaller chunks that can be easily processed.\n",
    "\n",
    "In summary, the `split_text` function provides a convenient way to break down lengthy PDF texts into manageable chunks for summarization, making it easier to process and extract key information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d855fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_newlines(serie):\n",
    "    serie = serie.replace('\\n', ' ')\n",
    "    serie = serie.replace('\\\\n', ' ')\n",
    "    serie = serie.replace('  ', ' ')\n",
    "    serie = serie.replace('  ', ' ')\n",
    "    return serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c690ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = remove_newlines(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26d5e4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'These new Guidelines maintain continuity with the previous Guidelines as far as possible, while updating some elements.The Guidelines are broadly consistent with the Basel standards with some further elaborated sections following the CRD mandate, particularly on CSRBB assessment and monitoring and non- satisfactory IRRBB internal systems.The EBA is mandated to specify in these Guidelines additional criteria for the assessment and monitoring by institutions of their credit spread risk arising from their non-trading book activities (CSRBB).The Guidelines provide a definition and the scope of application of CSRBB.They contain dedicated sections for CSRBB with specific provisions on the identification, assessment and monitoring of CSRBB.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_text(context, 1000)[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bee4f3",
   "metadata": {},
   "source": [
    "## 3. Generating summaries of the text chunks using OpenAI’s language models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d798404",
   "metadata": {},
   "source": [
    "The following code defines a function named `gpt3_completion` that takes in a prompt string and four optional parameters: `engine`, `temp`, `top_p`, and `tokens`.\n",
    "\n",
    "- `prompt = prompt.encode(encoding='ASCII',errors='ignore').decode()` encodes the prompt string to ASCII format and ignores any errors that may arise during encoding, and then decodes it back to a string.\n",
    "\n",
    "- `try:` and `except Exception as oops:` are used to handle any errors that may occur while executing the code inside the try block.\n",
    "\n",
    "- `response = openai.Completion.create(...)` sends a request to the OpenAI GPT-3 API to generate text completion based on the provided prompt, engine, temp, top_p, and tokens parameters. The response is stored in the response variable.\n",
    "\n",
    "- `return response.choices[0].text.strip()` extracts the generated text from the response object and removes any leading or trailing white spaces.\n",
    "\n",
    "If an error occurs during the execution of the try block, the function returns an error message containing the error information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f170f496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt3_completion(  prompt\n",
    "                    , engine='text-davinci-003'\n",
    "                    , temp=0.5\n",
    "                    , top_p=0.3\n",
    "                    , tokens=1000):\n",
    "\n",
    "    prompt = prompt.encode(encoding='ASCII',errors='ignore').decode()\n",
    "    try:\n",
    "        response = openai.Completion.create(\n",
    "        engine=engine,\n",
    "        prompt=prompt,\n",
    "        temperature=temp,\n",
    "        top_p=top_p,\n",
    "        max_tokens=tokens\n",
    "        )\n",
    "        return response.choices[0].text.strip()\n",
    "    except Exception as oops:\n",
    "        return \"GPT-3 error: %s\" % oops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c06897eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(document):\n",
    "  \n",
    "    # Calling the split function to split text\n",
    "    chunks = split_text(document)\n",
    "  \n",
    "    summaries = []\n",
    "    for chunk in chunks:\n",
    "        prompt = \"Please summarize the following document: \\n\"\n",
    "        summary = gpt3_completion(prompt + chunk)\n",
    "        if summary.startswith(\"GPT-3 error:\"):\n",
    "            continue\n",
    "        summaries.append(summary)\n",
    "  \n",
    "    return \"\".join(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ada9054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = context\n",
    "\n",
    "# Call the summrize function with the document as input\n",
    "summary = summarize(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d568973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213034\n"
     ]
    }
   ],
   "source": [
    "print(len(document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df741567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46628\n"
     ]
    }
   ],
   "source": [
    "print(len(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1d0e99f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ./data/Guidelines on IRRBB and CSRBB.txt \n",
      " ./data/Guidelines on IRRBB and CSRBB - Summary.txt\n"
     ]
    }
   ],
   "source": [
    "path       = './data/'\n",
    "filename_1 = 'Guidelines on IRRBB and CSRBB.txt'\n",
    "filename_2 = 'Guidelines on IRRBB and CSRBB - Summary.txt'\n",
    "\n",
    "# Join the path and filename\n",
    "filename_1 = os.path.join(path, filename_1)\n",
    "filename_2 = os.path.join(path, filename_2)\n",
    "\n",
    "# Print the resulting filepath\n",
    "print('\\n', filename_1, '\\n', filename_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18c35425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some text content to be saved\n",
    "text_content = document\n",
    "\n",
    "# Open a new file for writing using the UTF-8 encoding\n",
    "with open(filename_1, \"w\", encoding=\"utf-8\") as f:\n",
    "    # Write the text content to the file\n",
    "    f.write(text_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcc25c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some text content to be saved\n",
    "text_content = summary\n",
    "\n",
    "# Open a new file for writing using the UTF-8 encoding\n",
    "with open(filename_2, \"w\", encoding=\"utf-8\") as f:\n",
    "    # Write the text content to the file\n",
    "    f.write(text_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
